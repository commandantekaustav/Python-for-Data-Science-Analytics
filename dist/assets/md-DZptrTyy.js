import{b as s,o,w as i,g as e,B as t,v as u,x as d,C as l}from"./modules/vue-DYRo_Lls.js";import{I as p}from"./slidev/default-COya6M-5.js";import{u as c,f}from"./slidev/context-Yz-4lzjv.js";import"./index-Q9xIr-xQ.js";import"./modules/shiki-NVXounY8.js";const b={__name:"s8.md__slidev_474",setup(m){const{$clicksContext:n,$frontmatter:r}=c();return n.setup(),(g,a)=>(o(),s(p,u(d(l(f)(l(r),473))),{default:i(()=>a[0]||(a[0]=[e("h3",null,"Generators - Use Cases - Data Pipelines ðŸ”—",-1),e("h1",null,"Use Cases for Generators: Data Pipelines",-1),e("p",null,[e("strong",null,"Generators are exceptionally well-suited for building data pipelines, especially when dealing with large datasets that donâ€™t fit into memory.")],-1),e("p",null,[e("strong",null,"Explanation:")],-1),e("ul",null,[e("li",null,[e("code",null,"read_large_dataset"),t(" reads a file line by line (generator).")]),e("li",null,[e("code",null,"filter_data"),t(" filters lines based on a keyword (generator, takes input from "),e("code",null,"read_large_dataset"),t(").")]),e("li",null,[e("code",null,"process_data"),t(" processes each line (e.g., uppercase, generator, takes input from filter_data).")]),e("li",null,[e("code",null,"pipeline"),t(" chains these generators together.")]),e("li",null,[t("The "),e("code",null,"for"),t(" loop iterates through the "),e("em",null,"entire"),t(" pipeline, processing data in a memory-efficient stream, without loading the entire dataset into memory at any stage.")])],-1),e("p",null,[e("strong",null,"Generators are fundamental for building efficient and scalable data processing systems in Python!")],-1)])),_:1},16))}};export{b as default};
