import{b as o,o as i,w as l,g as e,B as t,v as u,x as p,C as n}from"./modules/vue-DYRo_Lls.js";import{I as m}from"./slidev/default-COya6M-5.js";import{u as c,f as g}from"./slidev/context-Yz-4lzjv.js";import"./index-Q9xIr-xQ.js";import"./modules/shiki-NVXounY8.js";const C={__name:"s8.md__slidev_471",setup(d){const{$clicksContext:r,$frontmatter:s}=c();return r.setup(),(f,a)=>(i(),o(m,u(p(n(g)(n(s),470))),{default:l(()=>a[0]||(a[0]=[e("h3",null,"Generators - Use Cases - Data Pipelines ðŸ”—",-1),e("h1",null,"Use Cases for Generators: Data Pipelines",-1),e("p",null,[e("strong",null,"Generators are exceptionally well-suited for building data pipelines, especially when dealing with large datasets that donâ€™t fit into memory.")],-1),e("p",null,[e("strong",null,"Generators in Data Pipelines: Memory Efficiency and Streaming")],-1),e("ul",null,[e("li",null,[e("strong",null,"Streaming Data:"),t(' Generators enable "streaming" data through the pipeline. Data is processed in chunks or items, one at a time, rather than loading the entire dataset into memory.')]),e("li",null,[e("strong",null,"Memory Efficiency:"),t(" Each stage of the pipeline can be implemented as a generator. The output of one generator (stage) is fed as input to the next generator (stage) "),e("em",null,"without"),t(" storing intermediate results in large lists or data structures in memory.")]),e("li",null,[e("strong",null,"Chaining Generators:"),t(" You can chain generator functions and expressions together to create complex data processing pipelines in a very memory-efficient way.")])],-1)])),_:1},16))}};export{C as default};
